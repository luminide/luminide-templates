# {{ cookiecutter.project_description }}

### Introduction
This repository contains source code generated by [Luminide](https://luminide.com). It may be used to train, validate and tune deep learning models for image classification. The following directory structure is assumed:
```
├── code (source code)
├── input (dataset)
└── output (working directory)
```

The dataset should have images inside a directory named `{{ cookiecutter.train_image_dir }}` and a CSV file named `{{ cookiecutter.train_metadata }}`. An example is shown below:

```
input
├── {{ cookiecutter.train_metadata }}
└── {{ cookiecutter.train_image_dir }}
    ├── 2017-06-16__12-24-20-930.jpg
    ├── 2017-06-02__16-48-57-866.jpg
    ├── 2017-06-12__13-18-07-707.jpg
```

The CSV file is expected to have labels under a column named `{{ cookiecutter.label_column }}` as in the example below:

```
{{ cookiecutter.image_column }},{{ cookiecutter.label_column }}
2017-06-16__12-24-20-930.jpg,PI_257599
2017-06-02__16-48-57-866.jpg,PI_154987
2017-06-12__13-18-07-707.jpg,PI_92270
```
If an item has multiple labels, they should be separated by a space character as shown.

### Using this repo with Luminide
- Configure your [Kaggle API token](https://github.com/Kaggle/kaggle-api) on the `Import Data` tab.
- Attach a Compute Server with a GPU (e.g. gcp-t4).
- On the `Import Data` data tab, choose Kaggle and then enter `anlthms/sorghum3` (User Dataset).
- For exploratory analysis, run [eda.ipynb](eda.ipynb).
- To train, use the `Run Experiment` menu.
- To monitor training progress, use the `Experiment Visualization` menu.
- To generate a report on the most recent training session, run report.sh from the `Run Experiment` tab. Make sure `Track Experiment` is checked. The results will be copied back to a file called `report.html`.
- To tune the hyperparameters, edit [sweep.yaml](sweep.yaml) as desired and launch a sweep from the `Run Experiment` tab. Tuned values will be copied back to a file called `config-tuned.yaml` along with visualizations in `sweep-results.html`.
- After an experiment is complete, use the file browser on the IDE interface to access the results on the IDE Server.
- Use the `Experiment Tracking` menu to track experiments.
- Launch inference.sh to create submission.csv and use submit.sh to upload it to Kaggle.

{%- if cookiecutter.data_subset_percentage != '100' %}

Note: As configured, the code trains on {{ cookiecutter.data_subset_percentage }}% of the data. To train on the entire dataset, edit `full.sh` and `fast.sh` to remove the `--subset` command line parameter so that the default value of 100 is used.
{%- endif %}


For more details on usage, see [Luminide documentation](https://luminide.readthedocs.io)
