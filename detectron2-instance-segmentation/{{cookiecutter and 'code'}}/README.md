# {{ cookiecutter.project_description }}

### Introduction
This repository contains source code generated by [Luminide](https://luminide.com). It may be used to train, validate and tune computer vision models for instance segmentation. The following directory structure is assumed:
```
├── code (source code)
├── input (dataset)
└── output (working directory)
```

The dataset should have images inside a directory named `{{ cookiecutter.train_image_dir }}` and a CSV file named `{{ cookiecutter.train_metadata }}`. An example is shown below:

```
input
├── {{ cookiecutter.train_metadata }}
└── {{ cookiecutter.train_image_dir }}
    ├── 0030fd0e6378.png
    ├── 8002cb321f8b.png
    ├── 80070f7fb5e2.png
```

The CSV file is expected to have class labels under a column named `{{ cookiecutter.label_column }}` and mask annotations under `{{ cookiecutter.annotation_column }}` as in the example below:

```
{{ cookiecutter.image_column }},{{ cookiecutter.annotation_column }},width,height,{{ cookiecutter.label_column }}
0030fd0e6378,118145 6 118849 7 119553 8 120257 8 120961 9 121665 10 122369 12 123074 13 123778 14 124482 15 125186 16 125890 17 126594 18 127298 19 128002 20 128706 21 129410 22 130114 23 130818 24 131523 24 132227 25 132931 25 133635 24 134339 24 135043 23 135748 21 136452 19 137157 16 137864 11 138573 4,704,520,shsy5y
0030fd0e6378,189036 1 189739 3 190441 6 191144 7 191848 8 192552 9 193256 10 193960 11 194664 11 195368 12 196072 12 196776 13 197480 13 198185 13 198889 13 199593 14 200297 13 201002 11 201706 10 202410 9 203115 7 203819 6 204523 5 205227 5 205932 3 206636 2 207340 1,704,520,shsy5y
```

The annotations are assumed to be run length encoded masks.

### Using this repo with Luminide
- Attach a Compute Server and download a dataset. An example dataset would be `https://www.kaggle.com/c/sartorius-cell-instance-segmentation/data`.
- Convert the dataset to COCO format by launching `prep.sh` using the `Run Experiment` tab.
- For exploratory analysis, run [eda.ipynb](eda.ipynb).
- To train, launch `full.sh` from the `Run Experiment` tab.
- To monitor training progress, use the `Experiment Visualization` menu.
- To generate a report on the most recent training session, run report.sh from the `Run Experiment` tab. Make sure `Track Experiment` is checked. The results will be copied back to a file called `report.html`.
- To tune the hyperparameters, edit [sweep.yaml](sweep.yaml) as desired and launch a sweep from the `Run Experiment` tab. Tuned values will be copied back to a file called `config-tuned.yaml` along with visualizations in `sweep-results.html`.
- After an experiment is complete, use the file browser on the IDE interface to access the results on the IDE Server.
- Use the `Experiment Tracking` menu to track experiments.

{% if cookiecutter.Kaggle == "True" -%}
- To use this repo for a Kaggle code competition:
    - Configure your [Kaggle API token](https://github.com/Kaggle/kaggle-api) on the `Import Data` tab.
    - Run [kaggle.sh](kaggle.sh) as a custom experiment to upload the code to Kaggle.
    - To create a submission, copy [kaggle.ipynb](kaggle.ipynb) to a new Kaggle notebook.
    - Add the notebook output of `https://www.kaggle.com/luminide/wheels2` as Data.
    - Add your dataset at `https://www.kaggle.com/<kaggle_username>/kagglecode` as Data.
    - Add the relevant competition dataset as Data.
    - Run the notebook after turning off the `Internet` setting.

{%- endif %}


For more detailed documentation, see the [Luminide Tutorial](https://docs.luminide.com/docs/tutorial)
