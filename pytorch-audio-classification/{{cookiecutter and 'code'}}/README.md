# {{ cookiecutter.project_description }}

### Introduction
This repository contains source code generated by [Luminide](https://luminide.com). It may be used to train, validate and tune deep learning models for audio classification. The following directory structure is assumed:
```
├── code (source code)
├── input (dataset)
└── output (working directory)
```

The dataset should have audio files inside a directory named `{{ cookiecutter.train_audio_dir }}` and a CSV file named `{{ cookiecutter.train_metadata }}`. An example is shown below:

```
input
├── {{ cookiecutter.train_metadata }}
└── {{ cookiecutter.train_audio_dir }}
    ├── 800113bb65efe69e.ogg
    ├── 8002cb321f8bfcdf.ogg
    ├── 80070f7fb5e2ccaa.ogg
```

The CSV file is expected to have labels under a column named `{{ cookiecutter.label_column }}` as in the example below:

```
{{ cookiecutter.file_column }},{{ cookiecutter.label_column }}
800113bb65efe69e.ogg,pacific_wren
8002cb321f8bfcdf.ogg,hermit_thrush pacific_wren
80070f7fb5e2ccaa.ogg,hermit_thrush
```
If an item has multiple labels, they should be separated by a space character as shown.

### Using this repo with Luminide
- Attach a Compute Server and download a dataset. An example dataset is available at gs://luminide-example-bird-calls.
- Run `install.sh` from the `Run Experiment` tab to install required software on the Compute Server.
- For exploratory analysis, run [eda.ipynb](eda.ipynb).
- To train, use the `Run Experiment` menu.
- To monitor training progress, use the `Experiment Visualization` menu.
- To generate a report on the most recent training session, run report.sh from the `Run Experiment` tab. Make sure `Track Experiment` is checked. The results will be copied back to a file called `report.html`.
- To tune the hyperparameters, edit [sweep.yaml](sweep.yaml) as desired and launch a sweep from the `Run Experiment` tab. Tuned values will be copied back to a file called `config-tuned.yaml` along with visualizations in `sweep-results.html`.
- After an experiment is complete, use the file browser on the IDE interface to access the results on the IDE Server.
- Use the `Experiment Tracking` menu to track experiments.

{% if cookiecutter.Kaggle == "True" -%}
- To use this repo for a Kaggle code competition:
    - Configure your [Kaggle API token](https://github.com/Kaggle/kaggle-api) on the `Import Data` tab.
    - Run [kaggle.sh](kaggle.sh) as a custom experiment to upload the code to Kaggle.
    - To create a submission, copy [kaggle.ipynb](kaggle.ipynb) to a new Kaggle notebook.
    - Add the notebook output of `https://www.kaggle.com/luminide/wheels1` as Data.
    - Add your dataset at `https://www.kaggle.com/<kaggle_username>/kagglecode` as Data.
    - Add the relevant competition dataset as Data.
    - Run the notebook after turning off the `Internet` setting.

{%- endif %}

{%- if cookiecutter.data_subset_percentage != '100' %}

Note: As configured, the code trains on {{ cookiecutter.data_subset_percentage }}% of the data. To train on the entire dataset, edit `full.sh` and `fast.sh` to remove the `--subset` command line parameter so that the default value of 100 is used.
{%- endif %}


For more details on usage, see [Luminide documentation](https://luminide.readthedocs.io)
